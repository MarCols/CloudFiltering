{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting albumentations\n",
      "  Downloading https://files.pythonhosted.org/packages/f6/c4/a1e6ac237b5a27874b01900987d902fe83cc469ebdb09eb72a68c4329e78/albumentations-0.4.3.tar.gz (3.2MB)\n",
      "Requirement already satisfied: numpy>=1.11.1 in c:\\users\\unive\\anaconda2\\envs\\anaconda3\\lib\\site-packages (from albumentations) (1.16.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\unive\\anaconda2\\envs\\anaconda3\\lib\\site-packages (from albumentations) (0.19.0)\n",
      "Collecting imgaug<0.2.7,>=0.2.5 (from albumentations)\n",
      "  Downloading https://files.pythonhosted.org/packages/ad/2e/748dbb7bb52ec8667098bae9b585f448569ae520031932687761165419a2/imgaug-0.2.6.tar.gz (631kB)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\unive\\anaconda2\\envs\\anaconda3\\lib\\site-packages (from albumentations) (3.12)\n",
      "Collecting opencv-python>=4.1.1 (from albumentations)\n",
      "  Downloading https://files.pythonhosted.org/packages/9c/88/06cdc6239013e13aec97f474638fc4e7c00e5b7fb954a1d0ec2a5fc8db7a/opencv_python-4.1.1.26-cp36-cp36m-win_amd64.whl (39.0MB)\n",
      "Requirement already satisfied: scikit-image>=0.11.0 in c:\\users\\unive\\anaconda2\\envs\\anaconda3\\lib\\site-packages (from imgaug<0.2.7,>=0.2.5->albumentations) (0.13.0)\n",
      "Requirement already satisfied: six in c:\\users\\unive\\anaconda2\\envs\\anaconda3\\lib\\site-packages (from imgaug<0.2.7,>=0.2.5->albumentations) (1.10.0)\n",
      "Requirement already satisfied: networkx>=1.8 in c:\\users\\unive\\anaconda2\\envs\\anaconda3\\lib\\site-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (1.11)\n",
      "Requirement already satisfied: pillow>=2.1.0 in c:\\users\\unive\\anaconda2\\envs\\anaconda3\\lib\\site-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (6.1.0)\n",
      "Requirement already satisfied: PyWavelets>=0.4.0 in c:\\users\\unive\\anaconda2\\envs\\anaconda3\\lib\\site-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (0.5.2)\n",
      "Requirement already satisfied: decorator>=3.4.0 in c:\\users\\unive\\anaconda2\\envs\\anaconda3\\lib\\site-packages (from networkx>=1.8->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (4.0.11)\n",
      "Building wheels for collected packages: albumentations, imgaug\n",
      "  Building wheel for albumentations (setup.py): started\n",
      "  Building wheel for albumentations (setup.py): finished with status 'done'\n",
      "  Created wheel for albumentations: filename=albumentations-0.4.3-cp36-none-any.whl size=66315 sha256=858bcd0420439e103566605b11c4779def4f543557f7d9368cebb803c22aa85c\n",
      "  Stored in directory: C:\\Users\\unive\\AppData\\Local\\pip\\Cache\\wheels\\20\\16\\8e\\d3bec34bf30adff30929226f0b83cc8c005b5af131f51db9d0\n",
      "  Building wheel for imgaug (setup.py): started\n",
      "  Building wheel for imgaug (setup.py): finished with status 'done'\n",
      "  Created wheel for imgaug: filename=imgaug-0.2.6-cp36-none-any.whl size=655016 sha256=15bb59bdeabc7460a9e37dc306fcb1617ecb09d7c681670871fbfbca26d48c33\n",
      "  Stored in directory: C:\\Users\\unive\\AppData\\Local\\pip\\Cache\\wheels\\97\\ec\\48\\0d25896c417b715af6236dbcef8f0bed136a1a5e52972fc6d0\n",
      "Successfully built albumentations imgaug\n",
      "Installing collected packages: imgaug, opencv-python, albumentations\n",
      "  Found existing installation: opencv-python 3.4.3.18\n",
      "    Uninstalling opencv-python-3.4.3.18:\n",
      "      Successfully uninstalled opencv-python-3.4.3.18\n",
      "Successfully installed albumentations-0.4.3 imgaug-0.2.6 opencv-python-4.1.1.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 19.2.3, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras-rectified-adam in c:\\users\\unive\\anaconda2\\envs\\anaconda3\\lib\\site-packages (0.17.0)\n",
      "Requirement already satisfied: Keras in c:\\users\\unive\\anaconda2\\envs\\anaconda3\\lib\\site-packages (from keras-rectified-adam) (2.1.4)\n",
      "Requirement already satisfied: numpy in c:\\users\\unive\\anaconda2\\envs\\anaconda3\\lib\\site-packages (from keras-rectified-adam) (1.16.1)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\unive\\anaconda2\\envs\\anaconda3\\lib\\site-packages (from Keras->keras-rectified-adam) (1.10.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\unive\\anaconda2\\envs\\anaconda3\\lib\\site-packages (from Keras->keras-rectified-adam) (3.12)\n",
      "Requirement already satisfied: scipy>=0.14 in c:\\users\\unive\\anaconda2\\envs\\anaconda3\\lib\\site-packages (from Keras->keras-rectified-adam) (0.19.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 19.2.3, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install albumentations\n",
    "!pip install keras-rectified-adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\unive\\Anaconda2\\envs\\anaconda3\\lib\\site-packages\\requests\\__init__.py:80: RequestsDependencyWarning: urllib3 (1.25.3) or chardet (3.0.3) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n"
     ]
    }
   ],
   "source": [
    "import os, glob\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import multiprocessing\n",
    "from copy import deepcopy\n",
    "from sklearn.metrics import precision_recall_curve, auc\n",
    "import keras\n",
    "import keras.backend as K\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import Callback\n",
    "from keras.applications.densenet import DenseNet201\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.models import Model, load_model\n",
    "from keras.utils import Sequence\n",
    "from albumentations import Compose, VerticalFlip, HorizontalFlip, Rotate, GridDistortion\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from numpy.random import seed\n",
    "seed(10)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(10)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_imgs_folder = '../../Kaggle/understanding_cloud_organization/test_images/'\n",
    "train_imgs_folder = '../../Kaggle/understanding_cloud_organization/train_images/'\n",
    "num_cores = multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image_Label</th>\n",
       "      <th>EncodedPixels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0011165.jpg_Fish</td>\n",
       "      <td>264918 937 266318 937 267718 937 269118 937 27...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0011165.jpg_Flower</td>\n",
       "      <td>1355565 1002 1356965 1002 1358365 1002 1359765...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0011165.jpg_Gravel</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0011165.jpg_Sugar</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>002be4f.jpg_Fish</td>\n",
       "      <td>233813 878 235213 878 236613 878 238010 881 23...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Image_Label                                      EncodedPixels\n",
       "0    0011165.jpg_Fish  264918 937 266318 937 267718 937 269118 937 27...\n",
       "1  0011165.jpg_Flower  1355565 1002 1356965 1002 1358365 1002 1359765...\n",
       "2  0011165.jpg_Gravel                                                NaN\n",
       "3   0011165.jpg_Sugar                                                NaN\n",
       "4    002be4f.jpg_Fish  233813 878 235213 878 236613 878 238010 881 23..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('../../Kaggle/understanding_cloud_organization/train.csv')\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>Class</th>\n",
       "      <th>Fish</th>\n",
       "      <th>Flower</th>\n",
       "      <th>Sugar</th>\n",
       "      <th>Gravel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0011165.jpg</td>\n",
       "      <td>{Flower, Fish}</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>002be4f.jpg</td>\n",
       "      <td>{Flower, Fish, Sugar}</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0031ae9.jpg</td>\n",
       "      <td>{Flower, Fish, Sugar}</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0035239.jpg</td>\n",
       "      <td>{Gravel, Flower}</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>003994e.jpg</td>\n",
       "      <td>{Gravel, Fish, Sugar}</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Image                  Class  Fish  Flower  Sugar  Gravel\n",
       "0  0011165.jpg         {Flower, Fish}     1       1      0       0\n",
       "1  002be4f.jpg  {Flower, Fish, Sugar}     1       1      1       0\n",
       "2  0031ae9.jpg  {Flower, Fish, Sugar}     1       1      1       0\n",
       "3  0035239.jpg       {Gravel, Flower}     0       1      0       1\n",
       "4  003994e.jpg  {Gravel, Fish, Sugar}     1       0      1       1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = train_df[~train_df['EncodedPixels'].isnull()]\n",
    "train_df['Image'] = train_df['Image_Label'].map(lambda x: x.split('_')[0])\n",
    "train_df['Class'] = train_df['Image_Label'].map(lambda x: x.split('_')[1])\n",
    "classes = train_df['Class'].unique()\n",
    "train_df = train_df.groupby('Image')['Class'].agg(set).reset_index()\n",
    "for class_name in classes:\n",
    "    train_df[class_name] = train_df['Class'].map(lambda x: 1 if class_name in x else 0)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dictionary for fast access to ohe vectors\n",
    "img_2_ohe_vector = {img:vec for img, vec in zip(train_df['Image'], train_df.iloc[:, 2:].values)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_imgs, val_imgs = train_test_split(train_df['Image'].values, \n",
    "                                        test_size=0.2, \n",
    "                                        stratify=train_df['Class'].map(lambda x: str(sorted(list(x)))), # sorting present classes in lexicographical order, just to be sure\n",
    "                                        random_state=2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenenerator(Sequence):\n",
    "    def __init__(self, images_list=None, folder_imgs=train_imgs_folder, \n",
    "                 batch_size=32, shuffle=True, augmentation=None,\n",
    "                 resized_height=260, resized_width=260, num_channels=3):\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.augmentation = augmentation\n",
    "        if images_list is None:\n",
    "            self.images_list = os.listdir(folder_imgs)\n",
    "        else:\n",
    "            self.images_list = deepcopy(images_list)\n",
    "        self.folder_imgs = folder_imgs\n",
    "        self.len = len(self.images_list) // self.batch_size\n",
    "        self.resized_height = resized_height\n",
    "        self.resized_width = resized_width\n",
    "        self.num_channels = num_channels\n",
    "        self.num_classes = 4\n",
    "        self.is_test = not 'train' in folder_imgs\n",
    "        if not shuffle and not self.is_test:\n",
    "            self.labels = [img_2_ohe_vector[img] for img in self.images_list[:self.len*self.batch_size]]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "    def on_epoch_start(self):\n",
    "        if self.shuffle:\n",
    "            random.shuffle(self.images_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        current_batch = self.images_list[idx * self.batch_size: (idx + 1) * self.batch_size]\n",
    "        X = np.empty((self.batch_size, self.resized_height, self.resized_width, self.num_channels))\n",
    "        y = np.empty((self.batch_size, self.num_classes))\n",
    "\n",
    "        for i, image_name in enumerate(current_batch):\n",
    "            path = os.path.join(self.folder_imgs, image_name)\n",
    "            img = cv2.resize(cv2.imread(path), (self.resized_height, self.resized_width)).astype(np.float32)\n",
    "            if not self.augmentation is None:\n",
    "                augmented = self.augmentation(image=img)\n",
    "                img = augmented['image']\n",
    "            X[i, :, :, :] = img/255.0\n",
    "            if not self.is_test:\n",
    "                y[i, :] = img_2_ohe_vector[image_name]\n",
    "        return X, y\n",
    "\n",
    "    def get_labels(self):\n",
    "        if self.shuffle:\n",
    "            images_current = self.images_list[:self.len*self.batch_size]\n",
    "            labels = [img_2_ohe_vector[img] for img in images_current]\n",
    "        else:\n",
    "            labels = self.labels\n",
    "        return np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
